# 07/11/25

General notes on open questions from supervisor meeting:

## Why not just use the filesystem as a database for graph data?



## Why use mmap for the HNSW data? Why does LMDB use it? How does LMDB achieve atomicity/durability?

https://db.cs.cmu.edu/papers/2022/cidr2022-p13-crotty.pdf - a good read on why it's an awful idea! LMDB uses it for a few reasons:
- it's just an on-disk B+ tree, zero-copy reads make read-heavy workloads super fast and generally the working set is small enough to fit in memory
- no need for a WAL, it uses copy-on-write and two 'meta-pages', and restricts itself to single write semantics. fsync is called on every write transaction commit, if fsync fails, the commit just fails and the transaction is aborted. the two meta-pages track the current state of the DB/pointer to current root node along with a txn-id, when you write you choose the older of the two meta-pages to write to. https://www.youtube.com/watch?v=PcQ7g9ekaCo

For the HNSW data, the tradeoffs are a little more difficult to make. The working set is larger and data is more volatile, but the DX gain/codebase simplicity of using mmap might outweigh the potential performance costs as outlined in the paper. Perhaps as extension could build a WAL/buffer manager specifically for the HNSW slabs.

## What does LMDB do for locking memory regions? Does it lock the entire memory region?



## Is OS paging really most efficient using mmap?



